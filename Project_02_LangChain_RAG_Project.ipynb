{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtn21327SSrmMCFPIZsoHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzair-DeVops/Quater-2/blob/main/Project_02_LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "KaeGa_h07QHe"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community pypdf -q langchain_google_genai  langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  --upgrade -q google-auth google-auth-oauthlib google-auth-httplib2  google-cloud\n"
      ],
      "metadata": {
        "id": "78KdZJZn-m2H"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 . **FIIRST** YOU NEED TO DOWNLOAD DESRIED PDF FILE AND UPLOAD IT TO COLAB\n",
        "HERE IS THE FILE LINK : https://drive.google.com/file/d/1D85ntKHxp6zhJerqFbGe4OZh_NkpZRBb/view?usp=sharing\n"
      ],
      "metadata": {
        "id": "cPqqS_aqe2dI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 . Loading Pdf"
      ],
      "metadata": {
        "id": "CIxEa2K2gGHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
        "data = loader.load()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9gRMXlzw7XRt"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXC4wAQ1_ohu",
        "outputId": "4c1cfce3-43ef-4f9b-dd4e-2bee76e910c5"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 . Spliting text"
      ],
      "metadata": {
        "id": "WA4svhSRgNyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
        "docs = text_splitter.split_documents(data)\n",
        "\n",
        "\n",
        "print(\"total number of documents : \" ,len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mWhmF-L9WZO",
        "outputId": "4b34b5fb-50ef-484e-8e44-e76a7e6f8231"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of documents :  43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 . Using API key"
      ],
      "metadata": {
        "id": "ZFQ9qTwIgTSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY_3')"
      ],
      "metadata": {
        "id": "MuaczszY9aPW"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 . HERE YOU NEED TO DOWNLOAD ANOTHER FILE AND UPLOAD IT TO COLBA :\n",
        "HERE IS THE LINK : https://drive.google.com/file/d/1afKObnhCZ9UeXyMuqiV2t4BJ9Nkvgm4D/view?usp=sharing"
      ],
      "metadata": {
        "id": "FmzZwN82fvwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 . Using json file"
      ],
      "metadata": {
        "id": "52K9axV7gf7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/test.json\"\n"
      ],
      "metadata": {
        "id": "PniMMWbh9et4"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "N6Gtncmt9i7x"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 . Creating embedding model"
      ],
      "metadata": {
        "id": "tkIPe_bygnM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\" , google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "cCULL_w1ACE6"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 . Embedding data and Retriver"
      ],
      "metadata": {
        "id": "zcY9DgLrgr60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=docs, embedding=embedding)\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n"
      ],
      "metadata": {
        "id": "tMr15taX9njF"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 . Creating LLM"
      ],
      "metadata": {
        "id": "6GhCfWIEgyQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash-exp\" , temperature = 0.3 , max_tokens=1000)"
      ],
      "metadata": {
        "id": "7_jvH7Ty-EC7"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11 . Defining user_prompt"
      ],
      "metadata": {
        "id": "hkzzRPmdg2hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "z7uj6Rvo-Kmj"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12 . Creating chains"
      ],
      "metadata": {
        "id": "CylzYEt-g7z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "14LA673E-M--"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12 . Asking question which is not in the pdf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0_A-VtXhg_0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\" : \"what is uzair\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmHfe2-YhMOr",
        "outputId": "e4b36cd3-4c26-4c23-c2d5-5efb2c58e06a"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but the provided context does not contain any information about \"uzair\". Therefore, I cannot answer your question.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13 . Asking question which is  in the pdf"
      ],
      "metadata": {
        "id": "5hWm8BFBhHBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\" : \"what is multi attention\"})\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM2kpxTT-TWq",
        "outputId": "e5c18c8f-23bf-4d6b-ddeb-546002f3352c"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-head attention is calculated by projecting the queries, keys, and values into multiple lower-dimensional spaces, performing attention in each space, and then concatenating and projecting the results. The formula is MultiHead(Q,K,V ) = Concat(head1,..., headh)WO where headi = Attention(QWQ\n",
            "i ,KW K\n",
            "i ,VW V\n",
            "i). In this model, 8 parallel attention layers, or heads, are used.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}